{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf46619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb906c06ad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, gunzip\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from gtfparse import read_gtf\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import qnorm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score \n",
    "from collections import Counter\n",
    "from scipy.spatial import distance\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9cad9c",
   "metadata": {},
   "source": [
    "### Helper function for gene length normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18db1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_length_normalization(df_input,gene_len_info):\n",
    "    gene_list = list(set(gencode.gene_name).intersection(set(df_input.index)))\n",
    "    df_input = df_input.loc[gene_list,:]\n",
    "    for gene in df_input.index:\n",
    "        df_input.loc[gene,:] = df_input.loc[gene,:]/gene_len_info.length[np.where(gene_len_info.gene_name==gene)[0][0]]\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1f489",
   "metadata": {},
   "source": [
    "### Read, clean, normalize and extract the rare biosample expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83aa7c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajoshi/.conda/envs/aj_env/lib/python3.8/site-packages/gtfparse/read_gtf.py:82: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  chunk_iterator = pd.read_csv(\n",
      "/home/ajoshi/.conda/envs/aj_env/lib/python3.8/site-packages/gtfparse/read_gtf.py:82: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  chunk_iterator = pd.read_csv(\n",
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid', 'artif_dupl']\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('../data/archs4_gene_human_v2.1.h5','r')\n",
    "x1 = f.get('data')\n",
    "x2 = x1.get('expression')\n",
    "exp_data = pd.DataFrame(data=x2)\n",
    "y1 = f.get('meta')\n",
    "y2 = y1.get('genes')\n",
    "gene_sym = y2.get('gene_symbol')\n",
    "gene_id = pd.DataFrame(data=gene_sym,columns=['gene_id'])\n",
    "gene_id = gene_id.iloc[:,0].apply(lambda s: s.decode('utf-8'))\n",
    "gene_id = pd.DataFrame(data=gene_id)\n",
    "y1 = f.get('meta')\n",
    "y3 = y1.get('samples')\n",
    "geo_acc = y3.get('geo_accession')\n",
    "samp_id = pd.DataFrame(data=geo_acc,columns=['geo_acc'])\n",
    "samp_id = samp_id.iloc[:,0].apply(lambda s: s.decode('utf-8'))\n",
    "samp_id = pd.DataFrame(data=samp_id)\n",
    "exp_data.columns = list(samp_id.iloc[:,0])\n",
    "exp_data.index = list(gene_id.iloc[:,0])\n",
    "sample_anno = pd.read_csv('../results/sample_annotations_multi_hot',sep='\\t',index_col=0)\n",
    "gencode = read_gtf(\"../../genome_25kb/data/gencode.v41.annotation.gtf\")\n",
    "gene_len_info = pd.read_csv('../results/gene_length_longest_transcript',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c058de4",
   "metadata": {},
   "source": [
    "### We select only the brain biosamples to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45010cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp_data = exp_data[sample_anno.index[np.where(sample_anno.brain==1)[0]]]\n",
    "train_exp_data = qnorm.quantile_normalize(np.log2(1+train_exp_data),axis=1)\n",
    "train_exp_data = gene_length_normalization(train_exp_data,gene_len_info)\n",
    "train_exp_data = np.transpose(train_exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803337d",
   "metadata": {},
   "source": [
    "### Prepare the data for GAN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738d1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.zeros(len(train_exp_data))\n",
    "train_data = torch.tensor(train_exp_data.to_numpy())\n",
    "train_set = [\n",
    "    (train_data[i], train_labels[i]) for i in range(len(train_exp_data))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50185d2",
   "metadata": {},
   "source": [
    "### Create a data loader for Pytorch, with train labels for the specific implementation, even though the purpose is unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af29507",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a6be8",
   "metadata": {},
   "source": [
    "### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc1ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(59425, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd6493",
   "metadata": {},
   "source": [
    "### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5c8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(59425, 32768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32768, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 16384),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16384, 32768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32768, 59425),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc58a4",
   "metadata": {},
   "source": [
    "### Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7980eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "momentum = 0.2 #If using SGD with momentum as optimization\n",
    "alpha = 0.2 #Learning rate decay, if using Adaptive gradient\n",
    "num_epochs = 100\n",
    "betas = (0.5,0.7) #If using Adam optimizer\n",
    "loss_function = nn.BCELoss() # Binary Cross-entropy as an objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e005751",
   "metadata": {},
   "source": [
    "### Set the optimization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "534bf0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c06677",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e62f8eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss D.: 0.6933845281600952 Loss G.: 0.7017270922660828\n",
      "Epoch: 10 Loss D.: 0.6914956569671631 Loss G.: 0.6982784867286682\n",
      "Epoch: 20 Loss D.: 0.6935787200927734 Loss G.: 0.6971633434295654\n",
      "Epoch: 30 Loss D.: 0.6919667720794678 Loss G.: 0.6942392587661743\n",
      "Epoch: 40 Loss D.: 0.7045297461067857 Loss G.: 0.6873991243294588\n",
      "Epoch: 50 Loss D.: 0.6113246239748767 Loss G.: 0.6982784867286682\n",
      "Epoch: 60 Loss D.: 0.5230754700153684 Loss G.: 0.6184592503772886\n",
      "Epoch: 70 Loss D.: 0.6735289040655383 Loss G.: 0.6129847763389083\n",
      "Epoch: 80 Loss D.: 0.7236504194890478 Loss G.: 0.5817390257843197\n",
      "Epoch: 90 Loss D.: 0.7973559903555498 Loss G.: 0.5239993452084663\n",
      "Epoch: 100 Loss D.: 0.7997487666305298 Loss G.: 0.5245890019488459\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, _) in enumerate(train_loader):\n",
    "        # Data for training the discriminator\n",
    "        real_samples_labels = torch.ones((batch_size, 1))\n",
    "        latent_space_samples = torch.randn((batch_size, 59425))\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat(\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "        )\n",
    "\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples.type(torch.float32))\n",
    "        loss_discriminator = loss_function(\n",
    "            output_discriminator, all_samples_labels)\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "        latent_space_samples = torch.randn((batch_size, 59425))\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "        loss_generator = loss_function(\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "        )\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # Show loss\n",
    "        if epoch % 10 == 0 and n == len(train_loader)-1:\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator} Loss G.: {loss_generator}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb2300",
   "metadata": {},
   "source": [
    "### Generate the synthetic 'brain' samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e0677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_samples = torch.randn(100, 59425)\n",
    "generated_samples = generator(latent_space_samples)\n",
    "generated_samples = generated_samples.detach()\n",
    "generated_samples_frame = pd.DataFrame(data=generated_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f6e7c",
   "metadata": {},
   "source": [
    "#### We choose a representative data example by finding the centroid of the brain samples in 59425 dimensions and then selecting the biosample closest to it. We compare all the generated biosamples with this representative biosample by computing the euclidean distance of all the generated biosamples from it, and viewing the histogram of these distances. The lower the scale of histogram and if most biosamples are towards teh lower end, the better the quality of the generated synthetic brain biosamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e93167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "centroid = np.mean(train_exp_data,axis=0)\n",
    "dists_from_centroid = [math.dist(centroid,train_exp_data.loc[sample,:]) for sample in train_exp_data.index]\n",
    "ind_of_min_dist = dists_from_centroid.index(min(dists_from_centroid))\n",
    "gen_biosamples_distances=[math.dist(train_exp_data.iloc[ind_of_min_dist,:],\n",
    "                                    generated_samples_frame.iloc[j,0:]) for j in range(len(generated_samples_frame))]\n",
    "hist = plt.hist(gen_biosamples_distances,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2bafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
